{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe6fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from vae import VAE, train_vae, reparameterize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55128ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be2228",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3595c7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get current working directory\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'datasets', 'mnist')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts to [0, 1] range\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root=DATA_DIR, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=DATA_DIR, train=False, transform=transform)\n",
    "\n",
    "# Split training into training and validation\n",
    "train_dataset, val_dataset = random_split(dataset, [50000, 10000])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128);\n",
    "\n",
    "# Visaulize some samples from training set\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "# Print the first few images in a row\n",
    "for i, (image, label) in enumerate(train_loader):\n",
    "    if i < 5:  # Print the first 5 samples\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(image[0].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Label: {label[0].item()}\")\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        break  # Exit the loop after printing 5 samples\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c05ee",
   "metadata": {},
   "source": [
    "### 1a. Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec499803",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "model = VAE(latent_dim=latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37c9e0",
   "metadata": {},
   "source": [
    "### 1b. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705f145",
   "metadata": {},
   "source": [
    "##### Define epochs and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088135c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadc022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss (ELBO): 935.53, Validation Loss (ELBO): 1459.25\n",
      "Epoch 2, Training Loss (ELBO): 1842.51, Validation Loss (ELBO): 2070.65\n",
      "Epoch 3, Training Loss (ELBO): 2190.67, Validation Loss (ELBO): 2346.35\n",
      "Epoch 4, Training Loss (ELBO): 2362.19, Validation Loss (ELBO): 2570.07\n",
      "Epoch 5, Training Loss (ELBO): 2532.10, Validation Loss (ELBO): 2809.39\n",
      "Epoch 6, Training Loss (ELBO): 2685.31, Validation Loss (ELBO): 2606.36\n",
      "Epoch 7, Training Loss (ELBO): 2784.60, Validation Loss (ELBO): 3070.15\n",
      "Epoch 8, Training Loss (ELBO): 2826.94, Validation Loss (ELBO): 3127.86\n",
      "Epoch 9, Training Loss (ELBO): 2925.19, Validation Loss (ELBO): 3111.68\n",
      "Epoch 10, Training Loss (ELBO): 2989.92, Validation Loss (ELBO): 2335.86\n",
      "Epoch 11, Training Loss (ELBO): 3011.11, Validation Loss (ELBO): 2902.04\n",
      "Epoch 12, Training Loss (ELBO): 3119.78, Validation Loss (ELBO): 3048.07\n",
      "Epoch 13, Training Loss (ELBO): 3088.15, Validation Loss (ELBO): 3052.78\n",
      "Epoch 14, Training Loss (ELBO): 3138.25, Validation Loss (ELBO): 3140.01\n",
      "Epoch 15, Training Loss (ELBO): 3144.83, Validation Loss (ELBO): 2787.56\n",
      "Epoch 16, Training Loss (ELBO): 3218.67, Validation Loss (ELBO): 3482.25\n",
      "Epoch 17, Training Loss (ELBO): 3198.30, Validation Loss (ELBO): 3403.21\n",
      "Epoch 18, Training Loss (ELBO): 3260.55, Validation Loss (ELBO): 3605.38\n",
      "Epoch 19, Training Loss (ELBO): 3263.95, Validation Loss (ELBO): 3346.30\n",
      "Epoch 20, Training Loss (ELBO): 3320.17, Validation Loss (ELBO): 2120.54\n",
      "Epoch 21, Training Loss (ELBO): 3281.31, Validation Loss (ELBO): 3148.47\n",
      "Epoch 22, Training Loss (ELBO): 3404.70, Validation Loss (ELBO): 3581.11\n",
      "Epoch 23, Training Loss (ELBO): 3440.67, Validation Loss (ELBO): 3640.81\n",
      "Epoch 24, Training Loss (ELBO): 3245.31, Validation Loss (ELBO): 2875.32\n",
      "Epoch 25, Training Loss (ELBO): 3316.36, Validation Loss (ELBO): 3241.97\n",
      "Epoch 26, Training Loss (ELBO): 3418.65, Validation Loss (ELBO): 3371.58\n",
      "Epoch 27, Training Loss (ELBO): 3395.69, Validation Loss (ELBO): 3726.42\n",
      "Epoch 28, Training Loss (ELBO): 3409.97, Validation Loss (ELBO): 3754.27\n",
      "Epoch 29, Training Loss (ELBO): 3474.30, Validation Loss (ELBO): 3434.06\n",
      "Epoch 30, Training Loss (ELBO): 3501.31, Validation Loss (ELBO): 3787.54\n",
      "Epoch 31, Training Loss (ELBO): 3393.68, Validation Loss (ELBO): 3687.87\n",
      "Epoch 32, Training Loss (ELBO): 3421.51, Validation Loss (ELBO): 3627.95\n",
      "Epoch 33, Training Loss (ELBO): 3398.49, Validation Loss (ELBO): 3377.62\n",
      "Epoch 34, Training Loss (ELBO): 3410.71, Validation Loss (ELBO): 3420.93\n",
      "Epoch 35, Training Loss (ELBO): 3468.28, Validation Loss (ELBO): 3766.31\n",
      "Epoch 36, Training Loss (ELBO): 3399.02, Validation Loss (ELBO): 3756.62\n",
      "Epoch 37, Training Loss (ELBO): 3451.28, Validation Loss (ELBO): 2807.20\n",
      "Epoch 38, Training Loss (ELBO): 3397.77, Validation Loss (ELBO): 3457.61\n",
      "Epoch 39, Training Loss (ELBO): 3384.39, Validation Loss (ELBO): 3648.17\n",
      "Epoch 40, Training Loss (ELBO): 3555.71, Validation Loss (ELBO): 3142.47\n",
      "Epoch 41, Training Loss (ELBO): 3499.86, Validation Loss (ELBO): 3672.15\n",
      "Epoch 42, Training Loss (ELBO): 3652.45, Validation Loss (ELBO): 3908.53\n",
      "Epoch 43, Training Loss (ELBO): 3434.40, Validation Loss (ELBO): 3870.22\n",
      "Epoch 44, Training Loss (ELBO): 3542.36, Validation Loss (ELBO): 3892.90\n",
      "Epoch 45, Training Loss (ELBO): 3487.57, Validation Loss (ELBO): 3367.55\n",
      "Epoch 46, Training Loss (ELBO): 3605.13, Validation Loss (ELBO): 3876.64\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, val_losses = train_vae(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer = optimizer,\n",
    "    device = device,\n",
    "    epochs=epochs,\n",
    "    patience=None   # No early stopping\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7609f",
   "metadata": {},
   "source": [
    "#### Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c50bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ELBO')  # clearer axis label\n",
    "plt.title('ELBO vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"negative_elbo_curve.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6c953",
   "metadata": {},
   "source": [
    "### 1c. Stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ead0eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss (ELBO): 2275.79, Validation Loss (ELBO): 2418.83\n",
      "Epoch 2, Training Loss (ELBO): 2301.15, Validation Loss (ELBO): 2356.98\n",
      "Epoch 3, Training Loss (ELBO): 2242.37, Validation Loss (ELBO): 2280.16\n",
      "Epoch 4, Training Loss (ELBO): 2342.48, Validation Loss (ELBO): 2034.17\n",
      "Epoch 5, Training Loss (ELBO): 2276.84, Validation Loss (ELBO): 1968.18\n",
      "Epoch 6, Training Loss (ELBO): 2280.09, Validation Loss (ELBO): 2391.08\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "patience = 5  # Early stopping criteria\n",
    "epochs = 100\n",
    "model, train_losses, val_losses = train_vae(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=epochs,\n",
    "    patience=5  # Enable early stopping\n",
    ")\n",
    "torch.save(model.state_dict(), \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffefbfd",
   "metadata": {},
   "source": [
    "### 1d. Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f031ebe",
   "metadata": {},
   "source": [
    "#### 1. Parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd49601",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate and load the model\n",
    "model = VAE(latent_dim=latent_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pt\", map_location=device, weights_only=True))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Generate Reconstruction Grid\n",
    "with torch.no_grad():\n",
    "    for x, _ in test_loader:\n",
    "        x = x.to(device)[:32]\n",
    "        x_recon, _, _, _, _ = model(x)\n",
    "        x_recon = torch.clamp(x_recon, 0, 1)\n",
    "        break\n",
    "\n",
    "grid_original = vutils.make_grid(x.cpu(), nrow=8, pad_value=1)\n",
    "grid_recon = vutils.make_grid(x_recon.cpu(), nrow=8, pad_value=1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 8))\n",
    "axs[0].imshow(grid_original.permute(1, 2, 0), cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title(\"Original Test Images\")\n",
    "\n",
    "axs[1].imshow(grid_recon.permute(1, 2, 0), cmap='gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title(\"Reconstructed Images\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"reconstruction_grid.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46447b1e",
   "metadata": {},
   "source": [
    "#### 2. Drawing sample from q(Z|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "432d97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for x, _ in test_loader:\n",
    "        x = x.to(device)[:32]\n",
    "        mu, logvar = model.encoder(x)\n",
    "        break\n",
    "z = reparameterize(mu, logvar).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e262a",
   "metadata": {},
   "source": [
    "#### 3.  Parameters of the distribu p(X|z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b55e4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "mu_x, logvar_x = model.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab07a2",
   "metadata": {},
   "source": [
    "#### 4. Sample an image x′ from p(X|z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed869bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(32, latent_dim).to(device)\n",
    "    mu_x, logvar_x = model.decoder(z)\n",
    "    x_sampled = reparameterize(mu_x, logvar_x)\n",
    "    x_sampled = torch.clamp(x_sampled, 0, 1)\n",
    "\n",
    "grid_samples = vutils.make_grid(x_sampled.cpu(), nrow=8, pad_value=1)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(grid_samples.permute(1, 2, 0), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Samples generated from Prior\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"samples_grid.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
